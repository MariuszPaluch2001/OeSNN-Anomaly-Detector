<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>OeSNN-AD.layer API documentation</title>
<meta name="description" content="Module contains definition and implementation of layer class." />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>OeSNN-AD.layer</code></h1>
</header>
<section id="section-intro">
<p>Module contains definition and implementation of layer class.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;
    Module contains definition and implementation of layer class.
&#34;&#34;&#34;

from typing import Generator, List, Tuple

import numpy as np
import numpy.typing as npt

from grf_init import GRFInit
from neuron import InputNeuron, Neuron, OutputNeuron


class Layer:
    &#34;&#34;&#34;
        Base class creates interface for inheritance classes.
        
        Beside of common attributes for all layers, class is making magic methods allowing
        indexation, counting numer of neurons in layer thank to &#39;len&#39; function.
        
        Class musn&#39;t be created as object.
    &#34;&#34;&#34;

    def __init__(self, num_neurons: int) -&gt; None:
        &#34;&#34;&#34;
            Args:
                num_neurons (int): Number of neurons in layer
        &#34;&#34;&#34;
        self.num_neurons = num_neurons

        self.neurons: List[Neuron]

    def __iter__(self) -&gt; Generator[Neuron, None, None]:
        &#34;&#34;&#34;
            Magic method for iteration over list of neurons in layer.

            Yields:
                Generator[Neuron, None, None]: generator which allow to iterate 
                over object&#39;s neurons
        &#34;&#34;&#34;
        return (neuron for neuron in self.neurons)

    def __len__(self) -&gt; int:
        &#34;&#34;&#34;
            Magic method returning count of neurons in layer.

            Returns:
                int: count of neurons in layer
        &#34;&#34;&#34;
        return len(self.neurons)

    def __getitem__(self, index: int) -&gt; Neuron:
        &#34;&#34;&#34;
            Magic method allowing to get neuron with usage of indexation.

            Args:
                index (int): index of neuron in list

            Returns:
                Neuron: neuron under index in list
        &#34;&#34;&#34;
        return self.neurons[index]

class InputLayer(Layer):
    &#34;&#34;&#34;
        Class implementing input layer, inheriting after base class Layer.
        
        Class stores and handling list of input neurons.
    &#34;&#34;&#34;

    def __init__(self, input_size: int) -&gt; None:
        &#34;&#34;&#34;
            Args:
                input_size (int): number of neurons in input layer
        &#34;&#34;&#34;
        super().__init__(input_size)

        self.neurons: List[InputNeuron] = [
            InputNeuron(0.0, id) for id in range(input_size)]

    def __iter__(self) -&gt; Generator[InputNeuron, None, None]:
        &#34;&#34;&#34;
            Magic method for iteration over list of input neurons in layer.

            Yields:
                Generator[InputNeuron, None, None]: generator which allow to iterate 
                over input neurons
        &#34;&#34;&#34;
        neurons = sorted(self.neurons, key=lambda neuron: neuron.order)
        return (neuron for neuron in neurons)

    def __getitem__(self, index: int) -&gt; InputNeuron:
        &#34;&#34;&#34;
            Magic method allowing to get input neuron with usage of indexation.

            Args:
                index (int): index of input neuron in list

            Returns:
                InputNeuron: input neuron under index in list
        &#34;&#34;&#34;
        return super().__getitem__(index)

    @property
    def orders(self) -&gt; np.vectorize:
        &#34;&#34;&#34; 
            Property, which lookup firing order of neurons in one list
            
            Returns:
                np.vectorize: vectorized list of firing order of neurons
        &#34;&#34;&#34;
        vectorized_get_order = np.vectorize(lambda neuron: neuron.order)
        return vectorized_get_order(self.neurons)

    def set_orders(self,
                   window: npt.NDArray[np.float64],
                   ts_coef: float,
                   mod: float,
                   beta: float) -&gt; None:
        &#34;&#34;&#34;  
            Method set for all input neurons new firing order in layer.

            Args:
                window (npt.NDArray[np.float64]): list of input values from stream
                ts_coef (float): factor from OeSNN-AD
                mod (float): factor from OeSNN-AD
                beta (float): factor from OeSNN-AD
        &#34;&#34;&#34;
        grf = GRFInit(window, self.num_neurons, ts_coef, mod, beta)

        for neuron, new_order in zip(self.neurons, grf.get_order()):
            neuron.set_order(new_order)

class OutputLayer(Layer):
    &#34;&#34;&#34;
        Class implementing output layer, inheriting after base class Layer.
        
        Class stores and handling list of output neurons.
    &#34;&#34;&#34;

    def __init__(self, max_output_size: int) -&gt; None:
        &#34;&#34;&#34;
            Args:
                max_output_size (int): Max number of output neurons in layer
        &#34;&#34;&#34;

        self.max_outpt_size = max_output_size
        self.neurons: List[OutputNeuron] = []

    def __iter__(self) -&gt; Generator[OutputNeuron, None, None]:
        &#34;&#34;&#34;
            Magic method for iteration over list of output neurons in layer.

            Yields:
                Generator[InputNeuron, None, None]: generator which allow to iterate 
                over output neurons
        &#34;&#34;&#34;
        return super().__iter__()

    def __getitem__(self, index: int) -&gt; OutputNeuron:
        &#34;&#34;&#34;
            Magic method allowing to get output neuron with usage of indexation.

            Args:
                index (int): index of output neuron in list

            Returns:
                OutputNeuron: output neuron under index in list
        &#34;&#34;&#34;
        return super().__getitem__(index)

    @property
    def num_neurons(self):
        return len(self.neurons)

    def make_candidate(self,
                       window: npt.NDArray[np.float64],
                       order: npt.NDArray[np.intp],
                       mod: float,
                       c_coef: float,
                       neuron_age: int) -&gt; OutputNeuron:
        &#34;&#34;&#34;
            Method is making new output neuron and setting his properties
            
            Args:
                window (npt.NDArray[np.float64]): list of values from stream
                order (npt.NDArray[np.intp]): firing order of neuron
                mod (float): factor from OeSNN-AD
                c_coef (float): factor from OeSNN-AD
                neuron_age (int): neuron&#39;s age

            Returns:
                OutputNeuron: Candidate neuron
        &#34;&#34;&#34;
        weights = mod ** order
        output_value = np.random.normal(np.mean(window), np.std(window))
        psp_max = (weights * (mod ** order)).sum()
        gamma = c_coef * psp_max

        return OutputNeuron(weights, gamma,
                            output_value, 1, neuron_age,
                            0, psp_max)

    def find_most_similar(self,
                          candidate_neuron: OutputNeuron) -&gt; Tuple[OutputNeuron | None, float]:
        &#34;&#34;&#34; 
            Method return neuron which have lowest euclidean distance to candidate neuron and that
            distance. If layer doesn&#39;t have neurons, method return Tuple[false, np.inf]
            
            Args:
                candidate_neuron (OutputNeuron): Neuron for which we need to find most similar

            Returns:
                Tuple[OutputNeuron | bool, float]: Two elements tuple, in which first position is
                for neuron or boolean false if layer is empty and second position is for
                euclidean distance (np.inf if layer is empty)
        &#34;&#34;&#34;
        if not self.neurons:
            return None, np.Inf

        dist_f = lambda neuron: np.linalg.norm(neuron.weights - candidate_neuron.weights)
        most_similar_neuron = min(self.neurons, key=dist_f)
        min_distance = dist_f(most_similar_neuron)
        return most_similar_neuron, min_distance

    def add_new_neuron(self, neuron: OutputNeuron) -&gt; None:
        &#34;&#34;&#34; 
            Method add new neuron when number of neurons is lower than max size of layer.
            
            Additionaly method after pushinh new neuron, update value of attribute num_neurons.

            Args:
                neuron (OutputNeuron): New neuron in layer
        &#34;&#34;&#34;
        self.neurons.append(neuron)

    def replace_oldest(self, candidate: OutputNeuron) -&gt; None:
        &#34;&#34;&#34;
            Method replace oldest neuron in layer by new created candidate, when number
            of neurons in layer is max.
            
            Args:
                candidate (OutputNeuron): new neuron which replace oldest neuron in layer
        &#34;&#34;&#34;
        oldest = min(self.neurons, key=lambda n: n.addition_time)
        self.neurons.remove(oldest)
        self.neurons.append(candidate)

    def reset_psp(self) -&gt; None:
        &#34;&#34;&#34; 
            Method zeroing postsynaptic potential all neurons in layer
        &#34;&#34;&#34;
        for neuron in self.neurons:
            neuron.psp = 0</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="OeSNN-AD.layer.InputLayer"><code class="flex name class">
<span>class <span class="ident">InputLayer</span></span>
<span>(</span><span>input_size: int)</span>
</code></dt>
<dd>
<div class="desc"><p>Class implementing input layer, inheriting after base class Layer.</p>
<p>Class stores and handling list of input neurons.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>input_size</code></strong> :&ensp;<code>int</code></dt>
<dd>number of neurons in input layer</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class InputLayer(Layer):
    &#34;&#34;&#34;
        Class implementing input layer, inheriting after base class Layer.
        
        Class stores and handling list of input neurons.
    &#34;&#34;&#34;

    def __init__(self, input_size: int) -&gt; None:
        &#34;&#34;&#34;
            Args:
                input_size (int): number of neurons in input layer
        &#34;&#34;&#34;
        super().__init__(input_size)

        self.neurons: List[InputNeuron] = [
            InputNeuron(0.0, id) for id in range(input_size)]

    def __iter__(self) -&gt; Generator[InputNeuron, None, None]:
        &#34;&#34;&#34;
            Magic method for iteration over list of input neurons in layer.

            Yields:
                Generator[InputNeuron, None, None]: generator which allow to iterate 
                over input neurons
        &#34;&#34;&#34;
        neurons = sorted(self.neurons, key=lambda neuron: neuron.order)
        return (neuron for neuron in neurons)

    def __getitem__(self, index: int) -&gt; InputNeuron:
        &#34;&#34;&#34;
            Magic method allowing to get input neuron with usage of indexation.

            Args:
                index (int): index of input neuron in list

            Returns:
                InputNeuron: input neuron under index in list
        &#34;&#34;&#34;
        return super().__getitem__(index)

    @property
    def orders(self) -&gt; np.vectorize:
        &#34;&#34;&#34; 
            Property, which lookup firing order of neurons in one list
            
            Returns:
                np.vectorize: vectorized list of firing order of neurons
        &#34;&#34;&#34;
        vectorized_get_order = np.vectorize(lambda neuron: neuron.order)
        return vectorized_get_order(self.neurons)

    def set_orders(self,
                   window: npt.NDArray[np.float64],
                   ts_coef: float,
                   mod: float,
                   beta: float) -&gt; None:
        &#34;&#34;&#34;  
            Method set for all input neurons new firing order in layer.

            Args:
                window (npt.NDArray[np.float64]): list of input values from stream
                ts_coef (float): factor from OeSNN-AD
                mod (float): factor from OeSNN-AD
                beta (float): factor from OeSNN-AD
        &#34;&#34;&#34;
        grf = GRFInit(window, self.num_neurons, ts_coef, mod, beta)

        for neuron, new_order in zip(self.neurons, grf.get_order()):
            neuron.set_order(new_order)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="OeSNN-AD.layer.Layer" href="#OeSNN-AD.layer.Layer">Layer</a></li>
</ul>
<h3>Instance variables</h3>
<dl>
<dt id="OeSNN-AD.layer.InputLayer.orders"><code class="name">var <span class="ident">orders</span> : numpy.vectorize</code></dt>
<dd>
<div class="desc"><p>Property, which lookup firing order of neurons in one list</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>np.vectorize</code></dt>
<dd>vectorized list of firing order of neurons</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def orders(self) -&gt; np.vectorize:
    &#34;&#34;&#34; 
        Property, which lookup firing order of neurons in one list
        
        Returns:
            np.vectorize: vectorized list of firing order of neurons
    &#34;&#34;&#34;
    vectorized_get_order = np.vectorize(lambda neuron: neuron.order)
    return vectorized_get_order(self.neurons)</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="OeSNN-AD.layer.InputLayer.set_orders"><code class="name flex">
<span>def <span class="ident">set_orders</span></span>(<span>self, window: numpy.ndarray[typing.Any, numpy.dtype[numpy.float64]], ts_coef: float, mod: float, beta: float) ‑> None</span>
</code></dt>
<dd>
<div class="desc"><p>Method set for all input neurons new firing order in layer.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>window</code></strong> :&ensp;<code>npt.NDArray[np.float64]</code></dt>
<dd>list of input values from stream</dd>
<dt><strong><code>ts_coef</code></strong> :&ensp;<code>float</code></dt>
<dd>factor from OeSNN-AD</dd>
<dt><strong><code>mod</code></strong> :&ensp;<code>float</code></dt>
<dd>factor from OeSNN-AD</dd>
<dt><strong><code>beta</code></strong> :&ensp;<code>float</code></dt>
<dd>factor from OeSNN-AD</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_orders(self,
               window: npt.NDArray[np.float64],
               ts_coef: float,
               mod: float,
               beta: float) -&gt; None:
    &#34;&#34;&#34;  
        Method set for all input neurons new firing order in layer.

        Args:
            window (npt.NDArray[np.float64]): list of input values from stream
            ts_coef (float): factor from OeSNN-AD
            mod (float): factor from OeSNN-AD
            beta (float): factor from OeSNN-AD
    &#34;&#34;&#34;
    grf = GRFInit(window, self.num_neurons, ts_coef, mod, beta)

    for neuron, new_order in zip(self.neurons, grf.get_order()):
        neuron.set_order(new_order)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="OeSNN-AD.layer.Layer"><code class="flex name class">
<span>class <span class="ident">Layer</span></span>
<span>(</span><span>num_neurons: int)</span>
</code></dt>
<dd>
<div class="desc"><p>Base class creates interface for inheritance classes.</p>
<p>Beside of common attributes for all layers, class is making magic methods allowing
indexation, counting numer of neurons in layer thank to 'len' function.</p>
<p>Class musn't be created as object.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>num_neurons</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of neurons in layer</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Layer:
    &#34;&#34;&#34;
        Base class creates interface for inheritance classes.
        
        Beside of common attributes for all layers, class is making magic methods allowing
        indexation, counting numer of neurons in layer thank to &#39;len&#39; function.
        
        Class musn&#39;t be created as object.
    &#34;&#34;&#34;

    def __init__(self, num_neurons: int) -&gt; None:
        &#34;&#34;&#34;
            Args:
                num_neurons (int): Number of neurons in layer
        &#34;&#34;&#34;
        self.num_neurons = num_neurons

        self.neurons: List[Neuron]

    def __iter__(self) -&gt; Generator[Neuron, None, None]:
        &#34;&#34;&#34;
            Magic method for iteration over list of neurons in layer.

            Yields:
                Generator[Neuron, None, None]: generator which allow to iterate 
                over object&#39;s neurons
        &#34;&#34;&#34;
        return (neuron for neuron in self.neurons)

    def __len__(self) -&gt; int:
        &#34;&#34;&#34;
            Magic method returning count of neurons in layer.

            Returns:
                int: count of neurons in layer
        &#34;&#34;&#34;
        return len(self.neurons)

    def __getitem__(self, index: int) -&gt; Neuron:
        &#34;&#34;&#34;
            Magic method allowing to get neuron with usage of indexation.

            Args:
                index (int): index of neuron in list

            Returns:
                Neuron: neuron under index in list
        &#34;&#34;&#34;
        return self.neurons[index]</code></pre>
</details>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="OeSNN-AD.layer.InputLayer" href="#OeSNN-AD.layer.InputLayer">InputLayer</a></li>
<li><a title="OeSNN-AD.layer.OutputLayer" href="#OeSNN-AD.layer.OutputLayer">OutputLayer</a></li>
</ul>
</dd>
<dt id="OeSNN-AD.layer.OutputLayer"><code class="flex name class">
<span>class <span class="ident">OutputLayer</span></span>
<span>(</span><span>max_output_size: int)</span>
</code></dt>
<dd>
<div class="desc"><p>Class implementing output layer, inheriting after base class Layer.</p>
<p>Class stores and handling list of output neurons.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>max_output_size</code></strong> :&ensp;<code>int</code></dt>
<dd>Max number of output neurons in layer</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class OutputLayer(Layer):
    &#34;&#34;&#34;
        Class implementing output layer, inheriting after base class Layer.
        
        Class stores and handling list of output neurons.
    &#34;&#34;&#34;

    def __init__(self, max_output_size: int) -&gt; None:
        &#34;&#34;&#34;
            Args:
                max_output_size (int): Max number of output neurons in layer
        &#34;&#34;&#34;

        self.max_outpt_size = max_output_size
        self.neurons: List[OutputNeuron] = []

    def __iter__(self) -&gt; Generator[OutputNeuron, None, None]:
        &#34;&#34;&#34;
            Magic method for iteration over list of output neurons in layer.

            Yields:
                Generator[InputNeuron, None, None]: generator which allow to iterate 
                over output neurons
        &#34;&#34;&#34;
        return super().__iter__()

    def __getitem__(self, index: int) -&gt; OutputNeuron:
        &#34;&#34;&#34;
            Magic method allowing to get output neuron with usage of indexation.

            Args:
                index (int): index of output neuron in list

            Returns:
                OutputNeuron: output neuron under index in list
        &#34;&#34;&#34;
        return super().__getitem__(index)

    @property
    def num_neurons(self):
        return len(self.neurons)

    def make_candidate(self,
                       window: npt.NDArray[np.float64],
                       order: npt.NDArray[np.intp],
                       mod: float,
                       c_coef: float,
                       neuron_age: int) -&gt; OutputNeuron:
        &#34;&#34;&#34;
            Method is making new output neuron and setting his properties
            
            Args:
                window (npt.NDArray[np.float64]): list of values from stream
                order (npt.NDArray[np.intp]): firing order of neuron
                mod (float): factor from OeSNN-AD
                c_coef (float): factor from OeSNN-AD
                neuron_age (int): neuron&#39;s age

            Returns:
                OutputNeuron: Candidate neuron
        &#34;&#34;&#34;
        weights = mod ** order
        output_value = np.random.normal(np.mean(window), np.std(window))
        psp_max = (weights * (mod ** order)).sum()
        gamma = c_coef * psp_max

        return OutputNeuron(weights, gamma,
                            output_value, 1, neuron_age,
                            0, psp_max)

    def find_most_similar(self,
                          candidate_neuron: OutputNeuron) -&gt; Tuple[OutputNeuron | None, float]:
        &#34;&#34;&#34; 
            Method return neuron which have lowest euclidean distance to candidate neuron and that
            distance. If layer doesn&#39;t have neurons, method return Tuple[false, np.inf]
            
            Args:
                candidate_neuron (OutputNeuron): Neuron for which we need to find most similar

            Returns:
                Tuple[OutputNeuron | bool, float]: Two elements tuple, in which first position is
                for neuron or boolean false if layer is empty and second position is for
                euclidean distance (np.inf if layer is empty)
        &#34;&#34;&#34;
        if not self.neurons:
            return None, np.Inf

        dist_f = lambda neuron: np.linalg.norm(neuron.weights - candidate_neuron.weights)
        most_similar_neuron = min(self.neurons, key=dist_f)
        min_distance = dist_f(most_similar_neuron)
        return most_similar_neuron, min_distance

    def add_new_neuron(self, neuron: OutputNeuron) -&gt; None:
        &#34;&#34;&#34; 
            Method add new neuron when number of neurons is lower than max size of layer.
            
            Additionaly method after pushinh new neuron, update value of attribute num_neurons.

            Args:
                neuron (OutputNeuron): New neuron in layer
        &#34;&#34;&#34;
        self.neurons.append(neuron)

    def replace_oldest(self, candidate: OutputNeuron) -&gt; None:
        &#34;&#34;&#34;
            Method replace oldest neuron in layer by new created candidate, when number
            of neurons in layer is max.
            
            Args:
                candidate (OutputNeuron): new neuron which replace oldest neuron in layer
        &#34;&#34;&#34;
        oldest = min(self.neurons, key=lambda n: n.addition_time)
        self.neurons.remove(oldest)
        self.neurons.append(candidate)

    def reset_psp(self) -&gt; None:
        &#34;&#34;&#34; 
            Method zeroing postsynaptic potential all neurons in layer
        &#34;&#34;&#34;
        for neuron in self.neurons:
            neuron.psp = 0</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="OeSNN-AD.layer.Layer" href="#OeSNN-AD.layer.Layer">Layer</a></li>
</ul>
<h3>Instance variables</h3>
<dl>
<dt id="OeSNN-AD.layer.OutputLayer.num_neurons"><code class="name">var <span class="ident">num_neurons</span></code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def num_neurons(self):
    return len(self.neurons)</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="OeSNN-AD.layer.OutputLayer.add_new_neuron"><code class="name flex">
<span>def <span class="ident">add_new_neuron</span></span>(<span>self, neuron: neuron.OutputNeuron) ‑> None</span>
</code></dt>
<dd>
<div class="desc"><p>Method add new neuron when number of neurons is lower than max size of layer.</p>
<p>Additionaly method after pushinh new neuron, update value of attribute num_neurons.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>neuron</code></strong> :&ensp;<code>OutputNeuron</code></dt>
<dd>New neuron in layer</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def add_new_neuron(self, neuron: OutputNeuron) -&gt; None:
    &#34;&#34;&#34; 
        Method add new neuron when number of neurons is lower than max size of layer.
        
        Additionaly method after pushinh new neuron, update value of attribute num_neurons.

        Args:
            neuron (OutputNeuron): New neuron in layer
    &#34;&#34;&#34;
    self.neurons.append(neuron)</code></pre>
</details>
</dd>
<dt id="OeSNN-AD.layer.OutputLayer.find_most_similar"><code class="name flex">
<span>def <span class="ident">find_most_similar</span></span>(<span>self, candidate_neuron: neuron.OutputNeuron) ‑> Tuple[neuron.OutputNeuron | None, float]</span>
</code></dt>
<dd>
<div class="desc"><p>Method return neuron which have lowest euclidean distance to candidate neuron and that
distance. If layer doesn't have neurons, method return Tuple[false, np.inf]</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>candidate_neuron</code></strong> :&ensp;<code>OutputNeuron</code></dt>
<dd>Neuron for which we need to find most similar</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>Tuple[OutputNeuron | bool, float]: Two elements tuple, in which first position is
for neuron or boolean false if layer is empty and second position is for
euclidean distance (np.inf if layer is empty)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def find_most_similar(self,
                      candidate_neuron: OutputNeuron) -&gt; Tuple[OutputNeuron | None, float]:
    &#34;&#34;&#34; 
        Method return neuron which have lowest euclidean distance to candidate neuron and that
        distance. If layer doesn&#39;t have neurons, method return Tuple[false, np.inf]
        
        Args:
            candidate_neuron (OutputNeuron): Neuron for which we need to find most similar

        Returns:
            Tuple[OutputNeuron | bool, float]: Two elements tuple, in which first position is
            for neuron or boolean false if layer is empty and second position is for
            euclidean distance (np.inf if layer is empty)
    &#34;&#34;&#34;
    if not self.neurons:
        return None, np.Inf

    dist_f = lambda neuron: np.linalg.norm(neuron.weights - candidate_neuron.weights)
    most_similar_neuron = min(self.neurons, key=dist_f)
    min_distance = dist_f(most_similar_neuron)
    return most_similar_neuron, min_distance</code></pre>
</details>
</dd>
<dt id="OeSNN-AD.layer.OutputLayer.make_candidate"><code class="name flex">
<span>def <span class="ident">make_candidate</span></span>(<span>self, window: numpy.ndarray[typing.Any, numpy.dtype[numpy.float64]], order: numpy.ndarray[typing.Any, numpy.dtype[numpy.int64]], mod: float, c_coef: float, neuron_age: int) ‑> neuron.OutputNeuron</span>
</code></dt>
<dd>
<div class="desc"><p>Method is making new output neuron and setting his properties</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>window</code></strong> :&ensp;<code>npt.NDArray[np.float64]</code></dt>
<dd>list of values from stream</dd>
<dt><strong><code>order</code></strong> :&ensp;<code>npt.NDArray[np.intp]</code></dt>
<dd>firing order of neuron</dd>
<dt><strong><code>mod</code></strong> :&ensp;<code>float</code></dt>
<dd>factor from OeSNN-AD</dd>
<dt><strong><code>c_coef</code></strong> :&ensp;<code>float</code></dt>
<dd>factor from OeSNN-AD</dd>
<dt><strong><code>neuron_age</code></strong> :&ensp;<code>int</code></dt>
<dd>neuron's age</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>OutputNeuron</code></dt>
<dd>Candidate neuron</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def make_candidate(self,
                   window: npt.NDArray[np.float64],
                   order: npt.NDArray[np.intp],
                   mod: float,
                   c_coef: float,
                   neuron_age: int) -&gt; OutputNeuron:
    &#34;&#34;&#34;
        Method is making new output neuron and setting his properties
        
        Args:
            window (npt.NDArray[np.float64]): list of values from stream
            order (npt.NDArray[np.intp]): firing order of neuron
            mod (float): factor from OeSNN-AD
            c_coef (float): factor from OeSNN-AD
            neuron_age (int): neuron&#39;s age

        Returns:
            OutputNeuron: Candidate neuron
    &#34;&#34;&#34;
    weights = mod ** order
    output_value = np.random.normal(np.mean(window), np.std(window))
    psp_max = (weights * (mod ** order)).sum()
    gamma = c_coef * psp_max

    return OutputNeuron(weights, gamma,
                        output_value, 1, neuron_age,
                        0, psp_max)</code></pre>
</details>
</dd>
<dt id="OeSNN-AD.layer.OutputLayer.replace_oldest"><code class="name flex">
<span>def <span class="ident">replace_oldest</span></span>(<span>self, candidate: neuron.OutputNeuron) ‑> None</span>
</code></dt>
<dd>
<div class="desc"><p>Method replace oldest neuron in layer by new created candidate, when number
of neurons in layer is max.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>candidate</code></strong> :&ensp;<code>OutputNeuron</code></dt>
<dd>new neuron which replace oldest neuron in layer</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def replace_oldest(self, candidate: OutputNeuron) -&gt; None:
    &#34;&#34;&#34;
        Method replace oldest neuron in layer by new created candidate, when number
        of neurons in layer is max.
        
        Args:
            candidate (OutputNeuron): new neuron which replace oldest neuron in layer
    &#34;&#34;&#34;
    oldest = min(self.neurons, key=lambda n: n.addition_time)
    self.neurons.remove(oldest)
    self.neurons.append(candidate)</code></pre>
</details>
</dd>
<dt id="OeSNN-AD.layer.OutputLayer.reset_psp"><code class="name flex">
<span>def <span class="ident">reset_psp</span></span>(<span>self) ‑> None</span>
</code></dt>
<dd>
<div class="desc"><p>Method zeroing postsynaptic potential all neurons in layer</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def reset_psp(self) -&gt; None:
    &#34;&#34;&#34; 
        Method zeroing postsynaptic potential all neurons in layer
    &#34;&#34;&#34;
    for neuron in self.neurons:
        neuron.psp = 0</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="OeSNN-AD" href="index.html">OeSNN-AD</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="OeSNN-AD.layer.InputLayer" href="#OeSNN-AD.layer.InputLayer">InputLayer</a></code></h4>
<ul class="">
<li><code><a title="OeSNN-AD.layer.InputLayer.orders" href="#OeSNN-AD.layer.InputLayer.orders">orders</a></code></li>
<li><code><a title="OeSNN-AD.layer.InputLayer.set_orders" href="#OeSNN-AD.layer.InputLayer.set_orders">set_orders</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="OeSNN-AD.layer.Layer" href="#OeSNN-AD.layer.Layer">Layer</a></code></h4>
</li>
<li>
<h4><code><a title="OeSNN-AD.layer.OutputLayer" href="#OeSNN-AD.layer.OutputLayer">OutputLayer</a></code></h4>
<ul class="two-column">
<li><code><a title="OeSNN-AD.layer.OutputLayer.add_new_neuron" href="#OeSNN-AD.layer.OutputLayer.add_new_neuron">add_new_neuron</a></code></li>
<li><code><a title="OeSNN-AD.layer.OutputLayer.find_most_similar" href="#OeSNN-AD.layer.OutputLayer.find_most_similar">find_most_similar</a></code></li>
<li><code><a title="OeSNN-AD.layer.OutputLayer.make_candidate" href="#OeSNN-AD.layer.OutputLayer.make_candidate">make_candidate</a></code></li>
<li><code><a title="OeSNN-AD.layer.OutputLayer.num_neurons" href="#OeSNN-AD.layer.OutputLayer.num_neurons">num_neurons</a></code></li>
<li><code><a title="OeSNN-AD.layer.OutputLayer.replace_oldest" href="#OeSNN-AD.layer.OutputLayer.replace_oldest">replace_oldest</a></code></li>
<li><code><a title="OeSNN-AD.layer.OutputLayer.reset_psp" href="#OeSNN-AD.layer.OutputLayer.reset_psp">reset_psp</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>